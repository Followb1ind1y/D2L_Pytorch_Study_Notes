{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsPRfibobfW9dE8JRMNYsN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Followb1ind1y/D2L_Pytorch_Study_Notes/blob/main/04_D2L_Linear_Neural_Networks_for_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Dive into Deep Learning Study Notes - Linear Neural Networks for Classification**"
      ],
      "metadata": {
        "id": "nMWAsjHz9n5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. Softmax Regression**"
      ],
      "metadata": {
        "id": "RFJA9Hdg-Lbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1.1. Classification**\n",
        "\n",
        "In general, classification problems do not come\n",
        "with natural orderings among the classes.\n",
        "Fortunately, statisticians long ago invented a simple way\n",
        "to represent categorical data: the ***one-hot encoding***.\n",
        "A one-hot encoding is a vector\n",
        "with as many components as we have categories.\n",
        "The component corresponding to a **particular instance's category is set to 1\n",
        "and all other components are set to 0**.\n",
        "In our case, a label $y$ would be a three-dimensional vector,\n",
        "with $(1, 0, 0)$ corresponding to \"cat\", $(0, 1, 0)$ to \"chicken\",\n",
        "and $(0, 0, 1)$ to \"dog\":\n",
        "\n",
        "$$y \\in \\{(1, 0, 0), (0, 1, 0), (0, 0, 1)\\}.$$"
      ],
      "metadata": {
        "id": "r88CPA5E3vE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.1.1. Linear Model**\n",
        "\n",
        "In order to estimate the conditional probabilities\n",
        "associated with all the possible classes,\n",
        "we need a model with **multiple outputs, one per class**.\n",
        "To address classification with linear models,\n",
        "we will need as many affine functions as we have outputs.\n",
        "Each output corresponds to its own affine function.\n",
        "In our case, since we have 4 features and 3 possible output categories,\n",
        "we need 12 scalars to represent the weights ($w$ with subscripts),\n",
        "and 3 scalars to represent the biases ($b$ with subscripts). This yields:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "o_1 &= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\\\\n",
        "o_2 &= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\\\\n",
        "o_3 &= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Just as in linear regression,\n",
        "we use a single-layer neural network.\n",
        "And since the calculation of each output, $o_1, o_2$, and $o_3$,\n",
        "depends on all inputs, $x_1$, $x_2$, $x_3$, and $x_4$,\n",
        "the output layer can also be described as a ***fully connected layer***.\n",
        "\n",
        "For a more concise notation we use vectors and matrices:\n",
        "$\\mathbf{o} = \\mathbf{W} \\mathbf{x} + \\mathbf{b}$ is\n",
        "much better suited for mathematics and code.\n",
        "Note that we have gathered all of our weights into a $3 \\times 4$ matrix and all biases\n",
        "$\\mathbf{b} \\in \\mathbb{R}^3$ in a vector."
      ],
      "metadata": {
        "id": "omjDDSVr4QyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.1.2. The Softmax**\n",
        "\n",
        "Assuming a suitable loss function,\n",
        "we could try, directly, to minimize the difference\n",
        "between $\\mathbf{o}$ and the labels $\\mathbf{y}$.\n",
        "While it turns out that treating classification\n",
        "as a vector-valued regression problem works surprisingly well,\n",
        "it is nonetheless lacking in the following ways:\n",
        "\n",
        "* There is **no guarantee that the outputs $o_i$ sum up to $1$** in the way we expect probabilities to behave.\n",
        "* There is **no guarantee that the outputs $o_i$ are even nonnegative, even if their outputs sum up to $1$**, or that they do not exceed $1$.\n",
        "\n",
        "One way to accomplish this goal\n",
        "(and to ensure nonnegativity) is to **use\n",
        "an exponential function** $P(y = i) \\propto \\exp o_i$.\n",
        "This does indeed satisfy the requirement\n",
        "that the conditional class probability\n",
        "increases with increasing $o_i$, it is monotonic,\n",
        "and all probabilities are nonnegative.\n",
        "We can then transform these values so that they add up to $1$\n",
        "by dividing each by their sum.\n",
        "**This process is called *normalization*.**\n",
        "Putting these two pieces together\n",
        "gives us the ***softmax* function**:\n",
        "\n",
        "$$\\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o}) \\quad \\text{where}\\quad \\hat{y}_i = \\frac{\\exp(o_i)}{\\sum_j \\exp(o_j)}.$$\n",
        "\n",
        "Note that **the largest coordinate of $\\mathbf{o}$\n",
        "corresponds to the most likely class according to $\\hat{\\mathbf{y}}$**.\n",
        "Moreover, because the softmax operation\n",
        "preserves the ordering among its arguments,\n",
        "we do not need to compute the softmax\n",
        "to determine which class has been assigned the highest probability.\n",
        "\n",
        "$$\n",
        "\\operatorname*{argmax}_j \\hat y_j = \\operatorname*{argmax}_j o_j.\n",
        "$$"
      ],
      "metadata": {
        "id": "OdcQmkXB6etl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.1.3. Vectorization**\n",
        "\n",
        "To improve computational efficiency,\n",
        "we vectorize calculations in minibatches of data.\n",
        "Assume that we are given a minibatch $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$\n",
        "of $n$ examples with dimensionality (number of inputs) $d$.\n",
        "Moreover, assume that we have $q$ categories in the output.\n",
        "Then the weights satisfy $\\mathbf{W} \\in \\mathbb{R}^{d \\times q}$\n",
        "and the bias satisfies $\\mathbf{b} \\in \\mathbb{R}^{1\\times q}$.\n",
        "\n",
        "$$ \\begin{aligned} \\mathbf{O} &= \\mathbf{X} \\mathbf{W} + \\mathbf{b}, \\\\ \\hat{\\mathbf{Y}} & = \\mathrm{softmax}(\\mathbf{O}). \\end{aligned} $$\n",
        "\n",
        "This accelerates the dominant operation into\n",
        "a matrix-matrix product $\\mathbf{X} \\mathbf{W}$.\n",
        "Moreover, since each row in $\\mathbf{X}$ represents a data example,\n",
        "the softmax operation itself can be computed *rowwise*:\n",
        "for each row of $\\mathbf{O}$, exponentiate all entries\n",
        "and then normalize them by the sum."
      ],
      "metadata": {
        "id": "D-fA-Ji6mEf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1.2. Loss Function**\n",
        "\n",
        "Now that we have a mapping from features $\\mathbf{x}$\n",
        "to probabilities $\\mathbf{\\hat{y}}$,\n",
        "**we need a way to optimize the accuracy of this mapping**.\n",
        "We will rely on maximum likelihood estimation,\n",
        "the very same concept that we encountered\n",
        "when providing a probabilistic justification\n",
        "for the mean squared error loss"
      ],
      "metadata": {
        "id": "QyFJ5KUhmg_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.2.1. Log-Likelihood**\n",
        "\n",
        "The softmax function gives us a vector $\\hat{\\mathbf{y}}$,\n",
        "which we can interpret as (estimated) conditional probabilities\n",
        "of each class, given any input $\\mathbf{x}$,\n",
        "such as $\\hat{y}_1$ = $P(y=\\text{cat} \\mid \\mathbf{x})$.\n",
        "In the following we assume that for a dataset\n",
        "with features $\\mathbf{X}$ the labels $\\mathbf{Y}$\n",
        "are represented using a one-hot encoding label vector.\n",
        "We can compare the estimates with reality\n",
        "by checking how probable the actual classes are\n",
        "according to our model, given the features:\n",
        "\n",
        "$$\n",
        "P(\\mathbf{Y} \\mid \\mathbf{X}) = \\prod_{i=1}^n P(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)}).\n",
        "$$\n",
        "\n",
        "We are allowed to use the factorization\n",
        "since we assume that each label is drawn independently\n",
        "from its respective distribution $P(\\mathbf{y}\\mid\\mathbf{x}^{(i)})$.\n",
        "Since maximizing the product of terms is awkward,\n",
        "we take the negative logarithm to obtain the equivalent problem\n",
        "of minimizing the negative log-likelihood:\n",
        "\n",
        "$$\n",
        "-\\log P(\\mathbf{Y} \\mid \\mathbf{X}) = \\sum_{i=1}^n -\\log P(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)})\n",
        "= \\sum_{i=1}^n l(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)}),\n",
        "$$\n",
        "\n",
        "where for any pair of label $\\mathbf{y}$\n",
        "and model prediction $\\hat{\\mathbf{y}}$\n",
        "over $q$ classes, the loss function $l$ is\n",
        "\n",
        "$$ l(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{j=1}^q y_j \\log \\hat{y}_j. $$\n",
        "\n",
        "The loss function in is commonly called the ***cross-entropy loss***.\n",
        "Since $\\mathbf{y}$ is a one-hot vector of length $q$,\n",
        "the sum over all its coordinates $j$ vanishes for all but one term."
      ],
      "metadata": {
        "id": "xXML-NcinPTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.2.2. Softmax and Cross-Entropy Loss**\n",
        "\n",
        "Plugging softmax into the cross-entropy loss and using the definition of the softmax we obtain:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "l(\\mathbf{y}, \\hat{\\mathbf{y}}) &=  - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\\n",
        "&= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j \\\\\n",
        "&= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "To understand a bit better what is going on,\n",
        "consider the derivative with respect to any logit $o_j$. We get\n",
        "\n",
        "$$\n",
        "\\partial_{o_j} l(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(\\mathbf{o})_j - y_j.\n",
        "$$\n",
        "\n",
        "In other words, the derivative is the difference\n",
        "between the probability assigned by our model,\n",
        "as expressed by the softmax operation,\n",
        "and what actually happened, as expressed\n",
        "by elements in the one-hot label vector.\n",
        "In this sense, it is very similar\n",
        "to what we saw in regression,\n",
        "where the gradient was the difference\n",
        "between the observation $y$ and estimate $\\hat{y}$."
      ],
      "metadata": {
        "id": "WyT6N-u0n10K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1.3. Information Theory Basics**\n",
        "\n",
        "***Information theory*** deals with the problem of encoding, decoding, transmitting, and manipulating information (also known as data)."
      ],
      "metadata": {
        "id": "o4NUG6Tlotqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.3.1. Entropy**\n",
        "\n",
        "The central idea in information theory is to **quantify the\n",
        "amount of information contained in data**.\n",
        "This places a limit on our ability to compress data.\n",
        "For a distribution $P$ its ***entropy*** is defined as:\n",
        "\n",
        "$$H[P] = \\sum_j - P(j) \\log P(j).$$\n"
      ],
      "metadata": {
        "id": "2kimYfYso7V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.3.2. Surprisal**\n",
        "\n",
        "Imagine that we have a stream of data that we want to compress.\n",
        "If it is always easy for us to predict the next token,\n",
        "then this data is easy to compress.\n",
        "\n",
        "However if we cannot perfectly predict every event,\n",
        "then we might sometimes be surprised.\n",
        "Our surprise is greater when we assigned an event lower probability.\n",
        "Claude Shannon settled on $\\log \\frac{1}{P(j)} = -\\log P(j)$\n",
        "to quantify one's ***surprisal*** at observing an event $j$\n",
        "having assigned it a (subjective) probability $P(j)$.\n",
        "The entropy is then the ***expected surprisal***\n",
        "when one assigned the correct probabilities\n",
        "that truly match the data-generating process."
      ],
      "metadata": {
        "id": "jQBa2QJupeHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1.3.3. Cross-Entropy Revisited**\n",
        "\n",
        "So if entropy is the level of surprise experienced\n",
        "by someone who knows the true probability,\n",
        "then what is cross-entropy?\n",
        "The **cross-entropy** *from* $P$ *to* $Q$, denoted $H(P, Q)$,\n",
        "is the **expected surprisal of an observer with subjective probabilities $Q$\n",
        "upon seeing data that was actually generated according to probabilities $P$**.\n",
        "This is given by $H(P, Q) \\stackrel{\\mathrm{def}}{=} \\sum_j - P(j) \\log Q(j)$.\n",
        "The lowest possible cross-entropy is achieved when $P=Q$.\n",
        "In this case, the cross-entropy from $P$ to $Q$ is $H(P, P)= H(P)$.\n",
        "\n",
        "In short, we can think of the cross-entropy classification objective\n",
        "in two ways: **(i) as maximizing the likelihood of the observed data**;\n",
        "and **(ii) as minimizing our surprisal (and thus the number of bits)\n",
        "required to communicate the labels**."
      ],
      "metadata": {
        "id": "pbWfAmzeqSak"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUz9Q9K59ucS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}